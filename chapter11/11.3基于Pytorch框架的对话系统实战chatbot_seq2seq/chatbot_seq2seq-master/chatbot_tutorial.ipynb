{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 使用PyTorch实现Chatbot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介\n",
    "本教程会介绍使用seq2seq模型实现一个chatbot，使用的训练数据来自[Cornell电影对话语料库](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)。本节中我们介绍使用seq2seq模型搭建一个聊天机器人。使用的训练数据来自康纳尔电影对话语料库。传统的对话系统要么基于检索的方法，提前准备一个问答库，根据用户的输入寻找类似的问题和答案。这样更像一个问答系统，它很难进行多轮的交互，而且答案是固定不变的。要么基于预先设置的对话流程，这主要用于填槽的任务，比如查询机票需要用户提供日期，达到城市等信息。这种方法的缺点是比较死板，如果用户的意图在设计的流程之外，那么就无法处理，而且对话的流程也一般比较固定，要支持用户随意的话题内跳转和话题间切换比较困难。\n",
    "目前研究热点是根据大量的对话数据，通过深度学习技术，自动的端到端的使用Seq2Seq模型学习对话模型。它的好处是不需要人来设计这个对话流程，完全是数据驱动的方法。它的缺点是流程不受人(开发者)控制，在严肃的场景(比如客服)下使用会有比较大的风险，而且需要大量的对话数据，这在很多实际应用中是很难得到的。这点在我们给移动公司打客服电话的时候，就会发现明显的改变。以前我们是听到语音提示，按键进行选择，而如今更多的是，让你说出你的需求，客服会根据你说出的需求，进行选择和回答。\n",
    "在本例中，我们将在PyTorch中实现这种模型，我们会分步骤具体讲解实现过程，具体实现代码会用灰色底纹标注。下面是具体实现后的对话效果示例：\n",
    "\n",
    "```\n",
    "> hello?\n",
    "Bot: hello .\n",
    "> where am I?\n",
    "Bot: you re in a hospital .\n",
    "> who are you?\n",
    "Bot: i m a lawyer .\n",
    "> how are you doing?\n",
    "Bot: i m fine .\n",
    "> are you my friend?\n",
    "Bot: no .\n",
    "> you're under arrest\n",
    "Bot: i m trying to help you !\n",
    "> i'm just kidding\n",
    "Bot: i m sorry .\n",
    "> where are you from?\n",
    "Bot: san francisco .\n",
    "> it's time for me to leave\n",
    "Bot: i know .\n",
    "> goodbye\n",
    "Bot: goodbye .\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备\n",
    "\n",
    "首先我们通过(http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip)下载训练语料库，这是一个zip文件，把它下载后到项目目录的子目录data下。接下来我们导入需要用到的模块，这主要是PyTorch的模块：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载和预处理数据\n",
    "\n",
    "接下来我们需要对原始数据进行变换然后用合适的数据结构加载到内存里。\n",
    "\n",
    "[Cornell电影对话语料库](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)是电影人物的对话数据，它包括：\n",
    "\n",
    "-  10,292对电影人物(一部电影有多个人物，他们两两之间可能存在对话)的220,579个对话\n",
    "-  617部电影的9,035个人物\n",
    "-  总共304,713个utterance(utterance是对话中的语音片段，不一定是完整的句子)\n",
    "\n",
    "该数据集庞大而多样，在语言形式、时间段、情感等方面有很大的变化。而我们的希望是，这种多样性使我们的模型，对多种形式的输入和查询具有鲁棒性。首先，我们将查看数据文件中部分行，以查看原始格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
     ]
    }
   ],
   "source": [
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "printLines(os.path.join(corpus, \"movie_lines.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理\n",
    "\n",
    "为了使用方便，我们会把原始数据处理成一个新的文件，这个新文件的每一行都是用TAB分割问题(query)和答案(response)对。为了实现这个目的，我们首先定义一些用于parsing原始文件 *movie_lines.txt*  的辅助函数。\n",
    "\n",
    " \n",
    "-  ``loadLines`` 把*movie_lines.txt* 文件切分成 (lineID, characterID, movieID, character, text)\n",
    "-  ``loadConversations`` 把上面的行group成一个个多轮的对话\n",
    "-  ``extractSentencePairs`` 从上面的每个对话中抽取句对\n",
    "将文件的每一行语料拆分都成一个字段字典，关键字是lineID、characterID、movieID、character和text，分别代表这一行的ID、人物ID、电影ID，人物名称和文本。最终输出一个字典，关键字是lineID，value是一个dict。value这个字典的关键字是lineID、characterID、movieID、character和text。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\\n\"\n"
     ]
    }
   ],
   "source": [
    "printLines(os.path.join(corpus, \"movie_conversations.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把每一行都parse成一个dict，key是lineID、characterID、movieID、character和text\n",
    "# 分别代表这一行的ID、人物ID、电影ID，人物名称和文本。\n",
    "# 最终输出一个dict，key是lineID，value是一个dict。\n",
    "# value这个dict的key是lineID、characterID、movieID、character和text\n",
    "#将文件的每一行拆分为一个字段字典\n",
    "def loadLines(fileName, fields):\n",
    "    lines = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # 抽取fields\n",
    "            lineObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "    return lines\n",
    "\n",
    "\n",
    "# 接下来我们根据movie_conversations.txt文件内容和以上输出的lines，把发言组成对话，\n",
    "#最终输出一个列表。这个列表的每一个元素都是一个字典，关键字分别是character1ID、character2ID、movieID和utteranceIDs。\n",
    "#分别表示这对话的第一个人物的ID，第二个的ID，电影的ID以及它包含的utteranceIDs。最后根据lines，\n",
    "#，其数值是个列表，包含所有发言(以上得到的lines的值)。\n",
    "def loadConversations(fileName, lines, fields):\n",
    "    conversations = []\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # 提取字段\n",
    "            convObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                convObj[field] = values[i]\n",
    "           # convObj[\"utteranceIDs\"]是一个字符串，形如['L198', 'L199']\n",
    "            #我们用eval把这个字符串变成一个字符串的列表。\n",
    "            lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "            # # 根据lineIds构造一个数组，根据lineId去lines里检索出存储utterance对象。\n",
    "            convObj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "\n",
    "#接下来从对话中抽取句对，假设一段对话包含s1,s2,s3,s4这4个发言\n",
    "#那么就会返回3个句对：s1-s2,s2-s3和s3-s4。2-s3和s3-s4。\n",
    "\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # 遍历对话中的每一个句子，忽略最后一个句子，因为没有答案。\n",
    "        for i in range(len(conversation[\"lines\"]) - 1): \n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # 如果有空的句子就去掉 \n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们利用上面的3个函数对原始数据进行处理，最终得到formatted_movie_lines.txt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus...\n",
      "\n",
      "Loading conversations...\n",
      "\n",
      "Writing newly formatted file...\n",
      "\n",
      "Sample lines from file:\n",
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\r\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\r\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\r\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\n'\n",
      "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\\r\\n\"\n",
      "b'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "# 定义新的文件 \n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = '\\t'\n",
    "# 对分隔符delimiter进行decode，这里对tab进行decode结果并没有变\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# 初始化dict lines，list conversations以及前面我们介绍过的field的id数组。\n",
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "\n",
    "# 首先使用loadLines函数处理movie_lines.txt \n",
    "print(\"\\nProcessing corpus...\")\n",
    "lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
    "# 接着使用loadConversations处理上一步的结果，得到conversations\n",
    "print(\"\\nLoading conversations...\")\n",
    "conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n",
    "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n",
    "\n",
    "# 输出到一个新的csv文件\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    # 使用extractSentencePairs从conversations里抽取句对。\n",
    "    for pair in extractSentencePairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "\n",
    "# 输出一些行用于检查 \n",
    "print(\"\\nSample lines from file:\")\n",
    "printLines(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建词典\n",
    "\n",
    "\n",
    "接下来我们需要构建词典然后把问答句对加载到内存里。我们的输入是一个句对，每个句子都是词的序列，因为机器学习只能处理数值，因此我们需要建立词到数字ID的映射。为此，我们会定义一个Voc类，它会保存词到ID的映射，同时也保存反向的从ID到词的映射。\n",
    "除此之外，它还记录每个词出现的次数，以及总共出现的词的个数。这个类提供addWord方法来增加一个词，用addSentence方法来增加句子，也提供trim方法来去除低频的词。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预定义的token\n",
    "PAD_token = 0  # 表示填槽 \n",
    "SOS_token = 1  # 句子的开始 \n",
    "EOS_token = 2  # 句子的结束 \n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # 目前有SOS, EOS, PAD这3个token。\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # 删除频次小于min_count的token \n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # 重新构造词典 \n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "        \n",
    "        # 重新构造后词频就没有意义了(都是1)\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上面的Voc类我们就可以通过问答句对来构建词典了。但是在构建之前我们需要进行一些预处理。\n",
    "首先我们需要使用函数unicodeToAscii来把unicode字符变成ascii，比如把à变成a。\n",
    "注意，这里的代码只是用于处理西方文字，如果是中文，这个函数直接会丢弃掉。\n",
    "接下来把所有字母变成小写同时丢弃掉字母和常见标点(.!?)之外的所有字符。\n",
    "最后为了训练收敛，我们会用函数filterPairs去掉长度超过MAX_LENGTH的句子(句对)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 221282 sentence pairs\n",
      "Trimmed to 64271 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 18008\n",
      "\n",
      "pairs:\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10  # 句子最大长度是10个词(包括EOS等特殊词)\n",
    "\n",
    "# 把Unicode字符串变成ASCII\n",
    "# 参考https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    " \n",
    "def normalizeString(s):\n",
    "    # 变成小写、去掉前后空格，然后unicode变成ascii\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    # 在标点前增加空格，这样把标点当成一个词\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    # 字母和标点之外的字符都变成空格\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    # 因为把不用的字符都变成空格，所以可能存在多个连续空格\n",
    "    # 下面的正则替换把多个空格变成一个空格，最后去掉前后空格\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# 读取问答句对并且返回Voc词典对象 \n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # 文件每行读取到list lines中。 \n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # 每行用tab切分成问答两个句子，然后调用normalizeString函数进行处理。\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "def filterPair(p): \n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# 过滤太长的句对 \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# 使用上面的函数进行处理，返回Voc对象和句对的list \n",
    "def loadPrepareData(corpus, corpus_name, datafile):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# 装载 voc 和句子对\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(corpus, corpus_name, datafile)\n",
    "# 输出一些句对\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了收敛更快，我们可以去除掉一些低频词。这可以分为两步：\n",
    "1) 使用voc.trim函数去掉频次低于MIN_COUNT 的词。\n",
    "2) 去掉包含低频词的句子。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7823 / 18005 = 0.4345\n",
      "Trimmed from 64271 pairs to 53165, 0.8272 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # 阈值为3\n",
    "\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # 去掉voc中频次小于3的词 \n",
    "    voc.trim(MIN_COUNT)\n",
    "    # 保留的句对 \n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # 检查问题\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # 检查答案\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # 如果问题和答案都只包含高频词，我们才保留这个句对\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# 实际进行处理\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为模型准备数据\n",
    "\n",
    "前面我们构建了词典，并且对训练数据进行预处理并且滤掉一些句对，但是模型最终用到的是Tensor。最简单的办法是一次处理一个句对，那么上面得到的句对直接就可以使用。但是为了加快训练速度，尤其是重复利用GPU的并行能力，我们需要一次处理一个batch的数据。\n",
    "\n",
    "对于某些问题，比如图像来说，输入可能是固定大小的(或者通过预处理缩放成固定大小），但是对于文本来说，我们很难把一个二十个词的句子\"缩放\"成十个词同时还保持语义不变。但是为了充分利用GPU等计算自由，我们又必须变成固定大小的Tensor，因此我们通常会使用Padding的技巧，把短的句子补充上零使得输入大小是(batch, max_length)，这样通过一次就能实现一个batch数据的forward或者backward计算。当然padding的部分的结果是没有意义的，比如某个句子实际长度是5，而max_length是10，那么最终forward的输出应该是第5个时刻的输出，后面5个时刻计算是无用功。方向计算梯度的时候也是类似的，我们需要从第5个时刻开始反向计算梯度。为了提高效率，通常把长度接近的训练数据放到一个batch里面，这样无用的计算是最少的。因此我们通常把全部训练数据根据长度划分成一些组，比如长度小于4的一组，长度4到8的一组，长度8到12的一组，...。然后每次随机的选择一个组，再随机的从一组里选择batch个数据。不过本教程并没有这么做，而是每次随机的从所有pair里随机选择batch个数据。\n",
    "\n",
    "原始的输入通常是batch个list，表示batch个句子，因此自然的表示方法为(batch, max_length)，这种表示方法第一维是batch，每移动一个下标得到的是一个样本的max_length个词(包括padding)。因为RNN的依赖关系，我们在计算t+1时刻必须知道t时刻的结果，因此我们无法用多个核同时计算一个样本的forward。但是不同样本之间是没有依赖关系的，因此我们可以在根据t时刻batch样本的当前状态计算batch个样本的输出和新状态，然后再计算t+2时刻，...。为了便于GPU一次取出t时刻的batch个数据，我们通常把输入从(batch, max_length)变成(max_length, batch)，这样使得t时刻的batch个数据在内存(显存)中是连续的，从而读取效率更高。这个过程如下图所示，原始输入的大小是(batch=6, max_length=4)，转置之后变成(4,6)。这样某个时刻的6个样本数据在内存中是连续的。\n",
    "\n",
    "![](seq2seq_batches.png)\n",
    "\n",
    " \n",
    "因此我们会用一些工具函数来实现上述处理。\n",
    "\n",
    "``inputVar``函数把batch个句子padding后变成一个LongTensor，大小是(max_length, batch)，同时会返回一个大小是batch的list lengths，说明每个句子的实际长度，这个参数后面会传给PyTorch，从而在forward和backward计算的时候使用实际的长度。\n",
    "\n",
    "``outputVar``函数和``inputVar``类似，但是它输出的第二个参数不是lengths，而是一个大小为(max_length, batch)的mask矩阵(tensor)，某位是0表示这个位置是padding，1表示不是padding，这样做的目的是后面计算方便。当然这两种表示是等价的，只不过lengths表示更加紧凑，但是计算起来不同方便，而mask矩阵和outputVar直接相乘就可以把padding的位置给mask(变成0)掉，这在计算loss时会非常方便。\n",
    "\n",
    "``batch2TrainData`` 则利用上面的两个函数把一个batch的句对处理成合适的输入和输出Tensor。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[2463,   33,   51,   77, 2266],\n",
      "        [  66, 2387, 2779,   37,  164],\n",
      "        [   9,   36,  682,   36,    4],\n",
      "        [6257,   37,    4,    6,    2],\n",
      "        [   4,   12, 1982,    2,    0],\n",
      "        [   4, 5620,    4,    0,    0],\n",
      "        [   4, 1557,    2,    0,    0],\n",
      "        [   2,    2,    0,    0,    0]])\n",
      "lengths: tensor([8, 8, 7, 5, 4])\n",
      "target_variable: tensor([[ 247,  651,  112,   76,   25],\n",
      "        [ 117,  598,   77,   37,  200],\n",
      "        [   7,   76,  115,  112,  483],\n",
      "        [  24,    4,  159,  180, 2267],\n",
      "        [   6,    2,   94,   56,    4],\n",
      "        [   2,    0,    7,    9,   25],\n",
      "        [   0,    0,  141, 4997,  387],\n",
      "        [   0,    0,   83, 5451,    4],\n",
      "        [   0,    0,    6,    4,    2],\n",
      "        [   0,    0,    2,    2,    0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 0, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 0]], dtype=torch.uint8)\n",
      "max_target_len: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "#合并数据，相当于行列转置\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "# 记录 PAD_token的位置为0，其他的为1\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# 返回填充前(加入结束index EOS_token做标记)的长度和填充后的输入序列张量\n",
    "\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# 返回填充目标序列张量、填充掩码和最大目标长度\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# 返回给定batch对的所有项目\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    \n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# 验证例子\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)编码器\n",
    "我们聊天机器人是一个序列到序列(seq2seq)模型。seq2seq模型的目标是将变长序列作为输入，并使用固定大小的模型返回变长序列作为输出。\n",
    "研究发现，通过将两个独立的RNN循环神经网络结合起来，可以完成这一任务。一个RNN充当编码器，它将可变长度的输入序列编码为固定长度的上下文向量。理论上，这个上下文向量(RNN的最后一个隐含层)将包含输入机器人的查询句子的语义信息。第二个RNN是一个解码器，它接受一个输入单词和上下文向量，并返回序列中下一个单词的概率和一个在下一次迭代中使用的隐藏状态。\n",
    "我们的编码器的核心是由Kyunghyun Cho, Dzmitry Bahdanau, Fethi Bougares Holger Schwenk, Yoshua Bengio(京铉町、德米特里·巴达瑙、费蒂·布加勒斯·霍尔格·施文克、约书亚·本吉奥).等人发明的多层门循环单元。在2014年，使用 GRU的双向变体，这意味着基本上有两个独立的RNN：一个以正常的顺序输入输入序列，另一个以相反的顺序输入输入序列。每个网络的输出在 每个时间步骤求和。使用双向GRU将为我们提供编码过去和未来上下文的优势。(注意:embedding层用于在任意大小的特征空间中对我们的单词索引进行编码。对于我们的模型，此图层会将每个单词映射到大小为 hidden_size的特征空间。训练后，这些值会被编码成和他们相似的有意义词语。)\n",
    "最后，如果将填充的一批序列传递给RNN模块，我们必须分别使用torch.nn.utils.rnn.pack_padded_sequence和torch.nn.utils.rnn.pad_packed_sequence 在RNN传递时分别进行填充和反填充。\n",
    "计算流程图为：\n",
    "（1）将单词索引转换为词嵌入 embeddings。\n",
    "（2）为RNN模块打包填充batch序列。\n",
    "（3）通过GRU进行前向传播。\n",
    "（4）反填充。\n",
    "（5）对双向GRU输出求和。\n",
    "（6）返回输出和最终隐藏状态。\n",
    "输入：\n",
    "input_seq：一批输入句子; shape =(max_length，batch_size)\n",
    "input_lengths：batch中每个句子对应的句子长度列表;shape=(batch_size)\n",
    "hidden:隐藏状态;shape =(n_layers x num_directions，batch_size，hidden_size)\n",
    "输出：\n",
    "outputs：GRU最后一个隐藏层的输出特征(双向输出之和);\n",
    "shape =(max_length，batch_size，hidden_size)\n",
    "hidden：从GRU更新隐藏状态;shape =(n_layers x num_directions，batch_size，hidden_size)\n",
    "class EncoderRNN(nn.Module):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # 初始化GRU; input_size和hidden_size参数都设置为'hidden_size'\n",
    "    # 因为我们的输入大小是一个嵌入了多个特征的单词==hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "       # 将单词索引转换为词向量\n",
    "        embedded = self.embedding(input_seq)\n",
    "         # 为RNN模块填充一批batch序列\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "       # 正向通过GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "         # 打开填充\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # 双向GRU输出总和\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # 返回输出和最终隐藏状态\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)解码器\n",
    "解码器RNN以token-by-token(令牌传递)的方式生成响应语句。它使用编码器的上下文向量和内部隐藏状态来生成序列中的下一个单词。它持续生成单词，直到输出是EOS_token，这个表示句子的结尾。一个 vanilla seq2seq 解码器的常见问题是，如果我们只依赖于上下文向量来编码整个输入序列的含义，那么我们很可能会丢失信息。尤其是在处理长输入序列时，这极大地限制了我们的解码器的能力。\n",
    "为了解决这个问题，Dzmitry Bahdanau(德米特里·巴达诺).等人创建了一种“attention mechanism ”，允许解码器关注输入序列的某些部分，而不是在每一步都使用完全固定的上下文。\n",
    "在一个高的层级中，用解码器的当前隐藏状态和编码器输出来计算注意力。输出注意力的权重与输入序列具有相同的大小，允许我们将它们乘以编码器输出，给出一个加权和，表示要注意的编码器输出部分。\n",
    "Minh-Thang Luong, (明成 隆).等人通过创造“Global attention ”，改善了Bahdanau et al.的基础工作。关键的区别在于，对于“Global attention ”，我们考虑所有编码器的隐藏状态，而不是Dzmitry Bahdanau(德米特里·巴达诺)等人的“Local attention ”，它只考虑当前步中编码器的隐藏状态。另一个区别在于，通过“Global attention ”，我们仅使用当前步的解码器的隐藏状态来计算注意力权重。Dzmitry Bahdanau(德米特里·巴达诺)等人的注意力计算需要知道前一步中解码器的状态。 此外，Minh-Thang Luong(明成良).等人提供各种方法来计算编码器输出和解码器输出 之间的注意权重(能量)，称之为“score functions ”。\n",
    "总体而言，Global attention机制可以通过下述的流程图进行总结。请注意，我们将“Attention Layer ”用一个名为Attn的nn.Module来单独实现。 \n",
    "该模块的输出是经过softmax标准化后权重张量的大小(batch_size，1，max_length)。\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong 注意力layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "       \n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "    \n",
    "    # 根据给定的方法计算注意力(能量)  \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "           \n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # 转置max_length和batch_size尺寸\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # 返回softmax归一化概率得分\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经定义了注意力子模块，我们可以实现真实的解码器模型。对于解码器，我们将每次手动进行一批次的输入。这意味着我们的词嵌入张量和GRU输出都将具有相同大小(1，batch_size，hidden_size)。\n",
    "计算流程图：\n",
    "①　获取当前输入的词嵌入\n",
    "②　通过单向GRU进行前向传播\n",
    "③　通过2输出的当前GRU计算注意力权重\n",
    "④　将注意力权重乘以编码器输出以获得新的“weighted sum ”上下文向量\n",
    "⑤　使用Minh-Thang Luong, (明成 隆)公式5.(https://arxiv.org/pdf/1508.04025v3.pdf)连接加权上下文向量和GRU输出\n",
    "⑥　使用Minh-Thang Luong, (明成 隆)公式6.(https://arxiv.org/pdf/1508.04025v3.pdf)预测下一个单词\n",
    "⑦　返回输出和最终隐藏状态\n",
    "输入：\n",
    "input_step：每一步输入序列batch(一个单词);shape =(1，batch_size)\n",
    "last_hidden：GRU的最终隐藏层;shape =(n_layers x num_directions，batch_size，hidden_size)\n",
    "encoder_outputs：编码器模型的输出;shape =(max_length，batch_size，hidden_size)\n",
    "输出：\n",
    "output: 一个softmax标准化后的张量， 代表了每个单词在解码序列中是下一个输出单词的概率;shape =(batch_size，voc.num_words)\n",
    "hidden: GRU的最终隐藏状态;\n",
    "shape =(n_layers x num_directions，batch_size，hidden_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        \n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # 定义层\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # 注意：我们一次运行一个步骤(单词)\n",
    "        # 获取当前输入字的嵌入\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # 通过单向GRU转发\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # 从当前GRU输出计算注意力\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        \n",
    "        # 将注意力权重乘以编码器输出以获得新的“加权和 ”上下文向量\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "         # 使用Minh-Thang Luong, (明成 隆)等的公式5连接加权上下文向量和GRU输出\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        # context从(64, 1, 500)变成(64, 500)\n",
    "        context = context.squeeze(1)\n",
    "        # 拼接得到(64, 1000)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        # self.concat是一个矩阵(1000, 500)，\n",
    "        # self.concat(concat_input)的输出是(64, 500)\n",
    "        # 然后用tanh把输出返回变成(-1,1)，concat_output的shape是(64, 500)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "\n",
    "         # 使用Minh-Thang Luong, (明成 隆)等的公式6预测下一个单词\n",
    "        output = self.out(concat_output)\n",
    "        # 用softmax变成概率，表示当前时刻输出每个词的概率。\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # 返回输出和在最终隐藏状态\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练步骤\n",
    "\n",
    "由于我们处理的是批量填充序列，因此在计算损失时我们不能简单地考虑张量的所有元素。我们定义maskNLLLoss可以根据解码器的输出张量、 描述目标张量填充的binary mask张量来计算损失。该损失函数计算与mask tensor中的1对应的元素的平均负对数似然。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    # 计算实际的词的个数，因为padding是0，非padding是1，因此sum就可以得到词的个数\n",
    "    nTotal = mask.sum()\n",
    "    \n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 定义训练迭代\n",
    "\n",
    "\n",
    "PyTorch的RNN模块(RNN，LSTM，GRU)可以像任何其他非重复层一样使用，只需将整个输入序列(或一批序列)传递给它们。我们在编码器中使用GRU层就是这样的。实际情况是，在计算中有一个迭代过程，进行循环计算隐藏状态的每一步。或者每次只运行一个模块，在这种情况下，我们在训练过程中手动循环遍历序列，就像我们必须为解码器模型做的那样。只要你正确的维护这些模型的模块，就可以非常简单的实现训练模型。\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # 梯度清空\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # 设置device，从而支持GPU，当然如果没有GPU也能工作。\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # 初始化变量\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # 正向传递编码器\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # 创建初始解码器输入(从每个句子的SOS令牌开始)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # 将初始解码器隐藏状态设置为编码器的最终隐藏状态\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # 确定我们是否此次迭代使用teacher forcing\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # 通过解码器一次一步地转发一批次序列\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: 下一个输入是当前的目标\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # 计算并累计损失\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            #下一个输入是解码器自己的当前输出\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # 计算并累计损失\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # 执行反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    # 对encoder和decoder进行梯度裁剪\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # 更新参数\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练迭代过程\n",
    "\n",
    "\n",
    "现在终于将完整的训练步骤与数据结合在一起了。给定传递的模型、优化器、数据等，trainIters函数负责运行n_iterations的训练。 这个功能显而易见，因为我们通过train函数的完成了繁重工作。\n",
    "需要注意的一点是，当我们保存模型时，我们会保存一个包含编码器和解码器state_dicts(参数)、优化器的state_dicts、损失、迭代等的压缩包。以这种方式保存模型将为我们checkpoint,提供最大的灵活性。\n",
    "加载checkpoint后，我们将能够使用模型参数进行推理，或者我们可以在我们中断的地方继续训练。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # 随机选择n_iteration个batch的数据(pair)\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # # 初始化\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    #  训练循环\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        #从batch中提取字段\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # 训练一个batch的数据\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # 打印进度\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # 保存checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果测试\n",
    "\n",
    "在训练模型后，我们希望能够自己与机器人交谈。首先，我们必须定义我们希望模型如何解码编码输入。\n",
    "贪婪解码是我们在不使用 teacher forcing(使用来自先验时间步长的输出作为输入) 时在训练期间使用的解码方法。换句话说，对于每一步，我们只需从具有最高 softmax 值的 decoder_output 中选择单词。该解码方法在单步长级别上是最佳的。\n",
    "为了便于贪婪解码操作，我们定义了一个GreedySearchDecoder类。当运行时，类的实例化对象输入序列(input_seq)的大小是(input_seq length，1)， 标量输入(input_length)长度的张量和 max_length 来约束响应句子长度。使用以下计算流程图来评估输入句子：\n",
    "计算流程图\n",
    "(1)通过编码器模型前向计算。\n",
    "(2)准备编码器的最终隐藏层，作为解码器的第一个隐藏输入。\n",
    "(3)将解码器的第一个输入初始化为 SOS_token。\n",
    "(4)将初始化张量追加到解码后的单词中。\n",
    "(5)一次迭代解码一个单词token：\n",
    "①　通过解码器进行前向计算。\n",
    "②　获得最可能的单词token及其softmax分数。\n",
    "③　记录token和分数。\n",
    "④　准备当前token作为下一个解码器的输入。\n",
    "(6)返回收集到的词 tokens 和分数。\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # 通过编码器模型转发输入\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # 将编码器的最终隐藏层准备为解码器的第一个隐藏输入\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        #使用SOS_token初始化解码器输入\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # 初始化要附加已解码单词的张量\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # 循环，这里只使用长度限制，后面处理的时候把EOS去掉了。\n",
    "        for _ in range(max_length):\n",
    "            # 正向通过解码器\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "           # 获得最可能的单词标记及其softmax分数\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # 把解码结果保存到all_tokens和all_scores里\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # 准备当前令牌作为下一个解码器输入(添加维度)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # 返回收集到的词tokens和分数\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估文本\n",
    "\n",
    "\n",
    "我们已经定义了解码方法，可以编写用于评估字符串输入句子的函数。evaluate函数管理输入句子的低层级处理过程。我们首先使 用batch_size == 1将句子格式化为输入batch的单词索引。我们通过将句子的单词转换为相应的索引，并通过转换维度来为我们的模型准备张量。我们还创建了一个lengths张量，其中包含输入句子的长度。在这种情况下，lengths是标量，因为我们一次只评估一个句子(batch_size == 1)。接下来，我们使用我们的GreedySearchDecoder实例化后的对象(searcher)获得解码响应句子的张量。最后，我们将响应的索引转换为单 词并返回已解码单词的列表。\n",
    "evaluateInput充当聊天机器人的用户接口。调用时，将生成一个输入文本字段，我们可以在其中输入查询语句。在输入我们的输入句子并 按 Enter 后，我们的文本以与训练数据相同的方式标准化，并最终被输入到评估函数以获得解码的输出句子。我们循环这个过程，这样我们可 以继续与我们的机器人聊天直到我们输入“q ”或“quit ”。\n",
    "最后，如果输入的句子包含一个不在词汇表中的单词，我们会通过打印错误消息并提示用户输入另一个句子来优雅地处理。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### 格式化输入句子作为batch\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # 创建lengths张量\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # 转置batch的维度以匹配模型的期望\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # 放到合适的设备上(比如GPU)\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # 用searcher解码句子\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # ID变成词。\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # 获取输入句子\n",
    "            input_sentence = input('> ')\n",
    "            # 检查是否退出\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # 句子归一化\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # 格式化和打印回复句\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # 去掉EOS后面的内容\n",
    "            words = []\n",
    "            for word in output_words:\n",
    "                if word == 'EOS':\n",
    "                    break\n",
    "                elif word != 'PAD':\n",
    "                    words.append(word)\n",
    "            print('Bot:', ' '.join(words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和测试模型\n",
    "\n",
    "最后，我们开始运行模型。无论我们是否想要训练或测试聊天机器人模型，我们都必须初始化各个编码器和解码器模型。在接下来的部分，我们设置了所需的配置，选择从头开始，或者设置加载的检查点，并构建和初始化模型。您可以随意使用不同的模型配置来优化性能。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# 配置模型\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# 设置检查点以加载; 如果从头开始，则设置为None。\n",
    "loadFilename = None\n",
    "checkpoint_iter = 2\n",
    "  \n",
    "\n",
    "# 如果提供了loadFilename，则加载模型\n",
    "if loadFilename:\n",
    "    # 如果在同一台机器上加载，则对模型进行训练\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # 否则比如checkpoint是在GPU上得到的，但是我们现在又用CPU来训练或者测试，那么注释掉下面的代码\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# 初始化词向量\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# 初始化编码器和解码器模型\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# 使用合适的设备\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "如果要训练模型，请运行以下部分。\n",
    "首先我们设置训练参数，然后初始化我们的优化器，最后我们调用trainIters函数来运行我们的训练迭代。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.cpp:733.)\n",
      "  \n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:132: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:20.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Percent complete: 1.0%; Average loss: 8.9668\n",
      "Iteration: 2; Percent complete: 2.0%; Average loss: 8.8601\n",
      "Iteration: 3; Percent complete: 3.0%; Average loss: 8.7393\n",
      "Iteration: 4; Percent complete: 4.0%; Average loss: 8.4241\n",
      "Iteration: 5; Percent complete: 5.0%; Average loss: 8.1144\n",
      "Iteration: 6; Percent complete: 6.0%; Average loss: 7.6378\n",
      "Iteration: 7; Percent complete: 7.0%; Average loss: 6.9383\n",
      "Iteration: 8; Percent complete: 8.0%; Average loss: 6.9917\n",
      "Iteration: 9; Percent complete: 9.0%; Average loss: 6.5861\n",
      "Iteration: 10; Percent complete: 10.0%; Average loss: 6.6975\n",
      "Iteration: 11; Percent complete: 11.0%; Average loss: 6.4147\n",
      "Iteration: 12; Percent complete: 12.0%; Average loss: 6.1059\n",
      "Iteration: 13; Percent complete: 13.0%; Average loss: 5.7933\n",
      "Iteration: 14; Percent complete: 14.0%; Average loss: 5.5153\n",
      "Iteration: 15; Percent complete: 15.0%; Average loss: 5.5470\n",
      "Iteration: 16; Percent complete: 16.0%; Average loss: 5.4658\n",
      "Iteration: 17; Percent complete: 17.0%; Average loss: 5.2393\n",
      "Iteration: 18; Percent complete: 18.0%; Average loss: 5.1901\n",
      "Iteration: 19; Percent complete: 19.0%; Average loss: 4.9810\n",
      "Iteration: 20; Percent complete: 20.0%; Average loss: 4.7371\n",
      "Iteration: 21; Percent complete: 21.0%; Average loss: 4.9175\n",
      "Iteration: 22; Percent complete: 22.0%; Average loss: 4.7731\n",
      "Iteration: 23; Percent complete: 23.0%; Average loss: 4.9620\n",
      "Iteration: 24; Percent complete: 24.0%; Average loss: 4.9922\n",
      "Iteration: 25; Percent complete: 25.0%; Average loss: 4.9383\n",
      "Iteration: 26; Percent complete: 26.0%; Average loss: 5.0273\n",
      "Iteration: 27; Percent complete: 27.0%; Average loss: 4.6712\n",
      "Iteration: 28; Percent complete: 28.0%; Average loss: 4.6601\n",
      "Iteration: 29; Percent complete: 29.0%; Average loss: 4.7880\n",
      "Iteration: 30; Percent complete: 30.0%; Average loss: 4.8305\n",
      "Iteration: 31; Percent complete: 31.0%; Average loss: 4.8802\n",
      "Iteration: 32; Percent complete: 32.0%; Average loss: 4.5895\n",
      "Iteration: 33; Percent complete: 33.0%; Average loss: 4.8407\n",
      "Iteration: 34; Percent complete: 34.0%; Average loss: 4.7436\n",
      "Iteration: 35; Percent complete: 35.0%; Average loss: 4.9765\n",
      "Iteration: 36; Percent complete: 36.0%; Average loss: 4.7201\n",
      "Iteration: 37; Percent complete: 37.0%; Average loss: 4.8242\n",
      "Iteration: 38; Percent complete: 38.0%; Average loss: 4.6169\n",
      "Iteration: 39; Percent complete: 39.0%; Average loss: 4.5431\n",
      "Iteration: 40; Percent complete: 40.0%; Average loss: 4.5953\n",
      "Iteration: 41; Percent complete: 41.0%; Average loss: 4.6865\n",
      "Iteration: 42; Percent complete: 42.0%; Average loss: 4.7593\n",
      "Iteration: 43; Percent complete: 43.0%; Average loss: 4.6541\n",
      "Iteration: 44; Percent complete: 44.0%; Average loss: 4.7085\n",
      "Iteration: 45; Percent complete: 45.0%; Average loss: 4.6351\n",
      "Iteration: 46; Percent complete: 46.0%; Average loss: 4.9702\n",
      "Iteration: 47; Percent complete: 47.0%; Average loss: 4.7898\n",
      "Iteration: 48; Percent complete: 48.0%; Average loss: 4.6378\n",
      "Iteration: 49; Percent complete: 49.0%; Average loss: 4.8772\n",
      "Iteration: 50; Percent complete: 50.0%; Average loss: 4.4148\n",
      "Iteration: 51; Percent complete: 51.0%; Average loss: 4.9120\n",
      "Iteration: 52; Percent complete: 52.0%; Average loss: 4.6564\n",
      "Iteration: 53; Percent complete: 53.0%; Average loss: 4.4583\n",
      "Iteration: 54; Percent complete: 54.0%; Average loss: 4.6473\n",
      "Iteration: 55; Percent complete: 55.0%; Average loss: 4.5928\n",
      "Iteration: 56; Percent complete: 56.0%; Average loss: 4.8351\n",
      "Iteration: 57; Percent complete: 57.0%; Average loss: 4.7311\n",
      "Iteration: 58; Percent complete: 58.0%; Average loss: 4.6331\n",
      "Iteration: 59; Percent complete: 59.0%; Average loss: 4.5983\n",
      "Iteration: 60; Percent complete: 60.0%; Average loss: 4.6752\n",
      "Iteration: 61; Percent complete: 61.0%; Average loss: 4.3207\n",
      "Iteration: 62; Percent complete: 62.0%; Average loss: 4.5401\n",
      "Iteration: 63; Percent complete: 63.0%; Average loss: 4.9700\n",
      "Iteration: 64; Percent complete: 64.0%; Average loss: 4.7760\n",
      "Iteration: 65; Percent complete: 65.0%; Average loss: 4.5417\n",
      "Iteration: 66; Percent complete: 66.0%; Average loss: 4.4921\n",
      "Iteration: 67; Percent complete: 67.0%; Average loss: 4.6289\n",
      "Iteration: 68; Percent complete: 68.0%; Average loss: 4.5545\n",
      "Iteration: 69; Percent complete: 69.0%; Average loss: 4.3680\n",
      "Iteration: 70; Percent complete: 70.0%; Average loss: 4.8267\n",
      "Iteration: 71; Percent complete: 71.0%; Average loss: 4.6267\n",
      "Iteration: 72; Percent complete: 72.0%; Average loss: 4.7665\n",
      "Iteration: 73; Percent complete: 73.0%; Average loss: 4.3344\n",
      "Iteration: 74; Percent complete: 74.0%; Average loss: 4.3874\n",
      "Iteration: 75; Percent complete: 75.0%; Average loss: 4.4439\n",
      "Iteration: 76; Percent complete: 76.0%; Average loss: 4.4366\n",
      "Iteration: 77; Percent complete: 77.0%; Average loss: 4.6363\n",
      "Iteration: 78; Percent complete: 78.0%; Average loss: 4.4384\n",
      "Iteration: 79; Percent complete: 79.0%; Average loss: 4.3172\n",
      "Iteration: 80; Percent complete: 80.0%; Average loss: 4.5739\n",
      "Iteration: 81; Percent complete: 81.0%; Average loss: 4.3165\n",
      "Iteration: 82; Percent complete: 82.0%; Average loss: 4.4037\n",
      "Iteration: 83; Percent complete: 83.0%; Average loss: 4.5691\n",
      "Iteration: 84; Percent complete: 84.0%; Average loss: 4.4223\n",
      "Iteration: 85; Percent complete: 85.0%; Average loss: 4.6383\n",
      "Iteration: 86; Percent complete: 86.0%; Average loss: 4.5566\n",
      "Iteration: 87; Percent complete: 87.0%; Average loss: 4.3721\n",
      "Iteration: 88; Percent complete: 88.0%; Average loss: 4.3263\n",
      "Iteration: 89; Percent complete: 89.0%; Average loss: 4.3486\n",
      "Iteration: 90; Percent complete: 90.0%; Average loss: 4.5750\n",
      "Iteration: 91; Percent complete: 91.0%; Average loss: 4.4458\n",
      "Iteration: 92; Percent complete: 92.0%; Average loss: 4.3633\n",
      "Iteration: 93; Percent complete: 93.0%; Average loss: 4.4417\n",
      "Iteration: 94; Percent complete: 94.0%; Average loss: 4.4821\n",
      "Iteration: 95; Percent complete: 95.0%; Average loss: 4.3582\n",
      "Iteration: 96; Percent complete: 96.0%; Average loss: 4.6061\n",
      "Iteration: 97; Percent complete: 97.0%; Average loss: 4.5653\n",
      "Iteration: 98; Percent complete: 98.0%; Average loss: 4.6068\n",
      "Iteration: 99; Percent complete: 99.0%; Average loss: 4.3001\n",
      "Iteration: 100; Percent complete: 100.0%; Average loss: 4.5636\n"
     ]
    }
   ],
   "source": [
    "# 配置训练的超参数和优化器 \n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 100\n",
    "print_every = 1\n",
    "save_every = 500\n",
    "\n",
    "# 确保dropout layers在训练模型中\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# 初始化优化器 \n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# 开始训练\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试\n",
    "\n",
    "\n",
    "运行如下代码，开始与您的模型进行聊天了。同时，可以尝试通过调整模型和训练参数以及 自定义训练模型的数据来定制聊天机器人的行为。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> hello?\n",
      "Bot: i you .\n",
      "> how are you doing?\n",
      "Bot: i i you .\n",
      "> q\n"
     ]
    }
   ],
   "source": [
    "# 将dropout layers设置为eval模式 \n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# 构造searcher对象 \n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# 测试\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "上面介绍了怎么从零开始训练一个chatbot，读者可以用自己的数据训练一个chatbot试试，看看能不能用来解决一些实际业务问题。\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
